{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression\n",
        "\n",
        "Linear regression analysis is used to predict the value of a variable based on the value of another variable. The variable you want to predict is called the dependent variable. The variable you are using to predict the other variable's value is called the independent variable\n",
        "\n",
        "This week, your task involves conducting multi-class linear regression on batsmen salaries. You'll use the average runs scored per game and the strike rate as independent variables. The goal is to predict the salary as the dependent variable. Additionally, you'll be categorizing the data based on the years.\n",
        "\n",
        "The dataset is Data_Mendeley.csv given on GitHub. Feel free to create any new functions required."
      ],
      "metadata": {
        "id": "4OSeJ-R-y9s7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import important libraries\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "AZ77VEImzRW5"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "preparing data"
      ],
      "metadata": {
        "id": "2oQPpSttzqt6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mounting gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "df=pd.read_csv('/content/gdrive/MyDrive/Classroom/Assignment/Data_Mendeley.csv')\n",
        "df.columns"
      ],
      "metadata": {
        "id": "NgyvUuEMAVEr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa42f879-592d-4d0b-cb47-b8dbac4ceb51"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Id', 'Name', 'Year', 'Final Price', 'Role', 'Nationality', 'Team',\n",
              "       'Ent', 'Age', 'Matches', 'LMatches', 'Runs', 'LRuns', 'HS', 'LHS',\n",
              "       'Ave', 'LAve', 'StrRate', 'LStrRate', 'Fifties', 'LFifties', 'Hundreds',\n",
              "       'LHundreds', 'Fours', 'LFours', 'Sixes', 'LSixes', 'Catches',\n",
              "       'LCatches', 'Stumps', 'LStumps', 'Wkts', 'LWkts', 'Econ', 'LEcon',\n",
              "       'FourWkts', 'LFourWkts', 'FiveWkts', 'LFiveWkts', 'Indian',\n",
              "       'Specialist', 'Status'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=df[['Runs','StrRate']].copy()\n",
        "Y=df['Final Price'].values\n",
        "df['Year'] = df['Year'].astype('category') #categorising the data\n",
        "x_train, x_test, Y_train, Y_test = train_test_split(x, Y, test_size=0.3, random_state=1234)"
      ],
      "metadata": {
        "id": "C9C0MZOGzg7g"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Forward pass"
      ],
      "metadata": {
        "id": "LV9ROCrR1hQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(x):\n",
        "  pass"
      ],
      "metadata": {
        "id": "AgySD6Ac1DCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean Squared Loss"
      ],
      "metadata": {
        "id": "B3uHaq5x1i7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(y,y_pred): #Mean Squared Loss\n",
        "  pass"
      ],
      "metadata": {
        "id": "eP2rV0z21IaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement Linear regression here :)"
      ],
      "metadata": {
        "id": "0JoKzzr_1uvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train=Y_train.reshape(x_train.shape[0],1)\n",
        "Y_test=Y_test.reshape(x_test.shape[0],1)"
      ],
      "metadata": {
        "id": "k2W3q6eR1d2J"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linmodel(X, Y, alpha, iterations,lambda_):\n",
        "    m, n = X.shape\n",
        "    w = np.random.rand(n, 1)\n",
        "    b = 0\n",
        "    cost_history = []\n",
        "\n",
        "    for i in range(iterations):\n",
        "        f_wb = np.dot(X, w) + b\n",
        "\n",
        "        # Mean Squared Error cost function\n",
        "        cost = np.sum((f_wb-Y) ** 2) / (2 * m) + (lambda_*np.sum(w**2))/(2*m)   #to prevent overfitting\n",
        "\n",
        "        dw = (1/m) * np.dot(X.T, (f_wb - Y)) + (lambda_*w)/m\n",
        "        db = (1/m) * np.sum(f_wb - Y)\n",
        "\n",
        "        # Update weights and bias\n",
        "        w = w - alpha * dw\n",
        "        b = b - alpha * db\n",
        "\n",
        "        cost_history.append(cost)\n",
        "\n",
        "        if i % (iterations / 10) == 0:\n",
        "            print(f\"The cost after {i} iteration is {cost_history[-1]}\")\n",
        "\n",
        "    return w, b, cost_history\n"
      ],
      "metadata": {
        "id": "FlGTcJc1ImIY"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for year, group in df.groupby('Year'):\n",
        "    X = group[['Runs','StrRate']]\n",
        "    y = group[['Final Price']]\n",
        "    X_train, X_test, y_train, y_test= train_test_split(x, Y, test_size=0.3, random_state=1234)\n",
        "    y_train=y_train.reshape(X_train.shape[0],1)\n",
        "    y_test=y_test.reshape(X_test.shape[0],1)\n",
        "    w,b,c = linmodel(X_train,y_train,0.00001,10000,1)\n",
        "    y_pred=np.dot(X_test,w)+b\n",
        "    y_mean=y_pred.mean()\n",
        "    r2_value=1-(np.sum((y_test-y_pred)**2)/np.sum((y_test-y_mean)**2))\n",
        "    print(\"\")\n",
        "    r.append(print(f\"Year: {year},  Coefficients: {w.T}, Intercept: {b}\"))\n",
        "    print(\"\")\n",
        "    print(f\"the R squared value is {r2_value}\")\n",
        "    print(\" \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYtFStgA90ZT",
        "outputId": "6a1cd59f-031a-4357-f7e6-e2c07dcc5280"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cost after 0 iteration is 760620018831999.5\n",
            "The cost after 1000 iteration is 363646623546349.6\n",
            "The cost after 2000 iteration is 363533507225901.1\n",
            "The cost after 3000 iteration is 363421007501360.3\n",
            "The cost after 4000 iteration is 363309121011669.25\n",
            "The cost after 5000 iteration is 363197844414091.0\n",
            "The cost after 6000 iteration is 363087174384109.9\n",
            "The cost after 7000 iteration is 362977107615332.1\n",
            "The cost after 8000 iteration is 362867640819387.06\n",
            "The cost after 9000 iteration is 362758770725828.8\n",
            "\n",
            "Year: 2008,  Coefficients: [[ 78176.22513439 125117.45123962]], Intercept: 334154.32776374364\n",
            "\n",
            "the R squared value is 0.17311449050457028\n",
            " \n",
            "The cost after 0 iteration is 760617768927001.2\n",
            "The cost after 1000 iteration is 363646623559335.1\n",
            "The cost after 2000 iteration is 363533507238815.8\n",
            "The cost after 3000 iteration is 363421007514204.6\n",
            "The cost after 4000 iteration is 363309121024443.56\n",
            "The cost after 5000 iteration is 363197844426795.7\n",
            "The cost after 6000 iteration is 363087174396745.3\n",
            "The cost after 7000 iteration is 362977107627898.6\n",
            "The cost after 8000 iteration is 362867640831885.06\n",
            "The cost after 9000 iteration is 362758770738258.75\n",
            "\n",
            "Year: 2009,  Coefficients: [[ 78176.22513332 125117.45127056]], Intercept: 334154.3240018579\n",
            "\n",
            "the R squared value is 0.17311449048181615\n",
            " \n",
            "The cost after 0 iteration is 760621068766078.5\n",
            "The cost after 1000 iteration is 363646623546333.2\n",
            "The cost after 2000 iteration is 363533507225884.75\n",
            "The cost after 3000 iteration is 363421007501344.06\n",
            "The cost after 4000 iteration is 363309121011653.06\n",
            "The cost after 5000 iteration is 363197844414074.94\n",
            "The cost after 6000 iteration is 363087174384093.94\n",
            "The cost after 7000 iteration is 362977107615316.25\n",
            "The cost after 8000 iteration is 362867640819371.2\n",
            "The cost after 9000 iteration is 362758770725813.1\n",
            "\n",
            "Year: 2010,  Coefficients: [[ 78176.22513439 125117.45123958]], Intercept: 334154.32776850427\n",
            "\n",
            "the R squared value is 0.17311449050459915\n",
            " \n",
            "The cost after 0 iteration is 760621083286440.2\n",
            "The cost after 1000 iteration is 363646623539504.25\n",
            "The cost after 2000 iteration is 363533507219093.1\n",
            "The cost after 3000 iteration is 363421007494589.4\n",
            "The cost after 4000 iteration is 363309121004935.25\n",
            "The cost after 5000 iteration is 363197844407393.75\n",
            "The cost after 6000 iteration is 363087174377449.1\n",
            "The cost after 7000 iteration is 362977107608707.6\n",
            "The cost after 8000 iteration is 362867640812798.7\n",
            "The cost after 9000 iteration is 362758770719276.4\n",
            "\n",
            "Year: 2011,  Coefficients: [[ 78176.22513495 125117.45122331]], Intercept: 334154.32974683726\n",
            "\n",
            "the R squared value is 0.17311449051656547\n",
            " \n",
            "The cost after 0 iteration is 760618662634427.8\n",
            "The cost after 1000 iteration is 363646623545480.0\n",
            "The cost after 2000 iteration is 363533507225036.25\n",
            "The cost after 3000 iteration is 363421007500500.2\n",
            "The cost after 4000 iteration is 363309121010813.8\n",
            "The cost after 5000 iteration is 363197844413240.2\n",
            "The cost after 6000 iteration is 363087174383263.7\n",
            "The cost after 7000 iteration is 362977107614490.56\n",
            "The cost after 8000 iteration is 362867640818550.06\n",
            "The cost after 9000 iteration is 362758770724996.44\n",
            "\n",
            "Year: 2012,  Coefficients: [[ 78176.22513446 125117.45123755]], Intercept: 334154.3280156732\n",
            "\n",
            "the R squared value is 0.17311449050609407\n",
            " \n",
            "The cost after 0 iteration is 760619852258669.9\n",
            "The cost after 1000 iteration is 363646623544053.94\n",
            "The cost after 2000 iteration is 363533507223617.94\n",
            "The cost after 3000 iteration is 363421007499089.56\n",
            "The cost after 4000 iteration is 363309121009410.8\n",
            "The cost after 5000 iteration is 363197844411844.94\n",
            "The cost after 6000 iteration is 363087174381876.0\n",
            "The cost after 7000 iteration is 362977107613110.44\n",
            "The cost after 8000 iteration is 362867640817177.44\n",
            "The cost after 9000 iteration is 362758770723631.25\n",
            "\n",
            "Year: 2013,  Coefficients: [[ 78176.22513458 125117.45123415]], Intercept: 334154.3284288216\n",
            "\n",
            "the R squared value is 0.1731144905085933\n",
            " \n",
            "The cost after 0 iteration is 760623628641955.4\n",
            "The cost after 1000 iteration is 363646623541224.5\n",
            "The cost after 2000 iteration is 363533507220804.0\n",
            "The cost after 3000 iteration is 363421007496291.0\n",
            "The cost after 4000 iteration is 363309121006627.5\n",
            "The cost after 5000 iteration is 363197844409076.7\n",
            "The cost after 6000 iteration is 363087174379123.0\n",
            "The cost after 7000 iteration is 362977107610372.4\n",
            "The cost after 8000 iteration is 362867640814454.3\n",
            "The cost after 9000 iteration is 362758770720923.06\n",
            "\n",
            "Year: 2014,  Coefficients: [[ 78176.22513481 125117.45122741]], Intercept: 334154.3292484766\n",
            "\n",
            "the R squared value is 0.17311449051355077\n",
            " \n",
            "The cost after 0 iteration is 760622641155707.9\n",
            "The cost after 1000 iteration is 363646623546261.94\n",
            "The cost after 2000 iteration is 363533507225813.94\n",
            "The cost after 3000 iteration is 363421007501273.6\n",
            "The cost after 4000 iteration is 363309121011583.0\n",
            "The cost after 5000 iteration is 363197844414005.25\n",
            "The cost after 6000 iteration is 363087174384024.56\n",
            "The cost after 7000 iteration is 362977107615247.3\n",
            "The cost after 8000 iteration is 362867640819302.6\n",
            "The cost after 9000 iteration is 362758770725744.94\n",
            "\n",
            "Year: 2015,  Coefficients: [[ 78176.2251344  125117.45123941]], Intercept: 334154.3277891344\n",
            "\n",
            "the R squared value is 0.17311449050472394\n",
            " \n",
            "The cost after 0 iteration is 760622666497365.5\n",
            "The cost after 1000 iteration is 363646623550857.0\n",
            "The cost after 2000 iteration is 363533507230384.0\n",
            "The cost after 3000 iteration is 363421007505818.75\n",
            "The cost after 4000 iteration is 363309121016103.4\n",
            "The cost after 5000 iteration is 363197844418501.0\n",
            "The cost after 6000 iteration is 363087174388495.8\n",
            "The cost after 7000 iteration is 362977107619694.06\n",
            "The cost after 8000 iteration is 362867640823725.25\n",
            "The cost after 9000 iteration is 362758770730143.44\n",
            "\n",
            "Year: 2016,  Coefficients: [[ 78176.22513402 125117.45125036]], Intercept: 334154.3264579445\n",
            "\n",
            "the R squared value is 0.17311449049667216\n",
            " \n",
            "The cost after 0 iteration is 760620384610281.8\n",
            "The cost after 1000 iteration is 363646623546413.6\n",
            "The cost after 2000 iteration is 363533507225964.8\n",
            "The cost after 3000 iteration is 363421007501423.6\n",
            "The cost after 4000 iteration is 363309121011732.25\n",
            "The cost after 5000 iteration is 363197844414153.6\n",
            "The cost after 6000 iteration is 363087174384172.2\n",
            "The cost after 7000 iteration is 362977107615394.06\n",
            "The cost after 8000 iteration is 362867640819448.6\n",
            "The cost after 9000 iteration is 362758770725890.1\n",
            "\n",
            "Year: 2017,  Coefficients: [[ 78176.22513438 125117.45123977]], Intercept: 334154.32774519944\n",
            "\n",
            "the R squared value is 0.17311449050445826\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression\n",
        "\n",
        "Logistic regression is a process of modeling the probability of a discrete outcome given an input variable. The most common logistic regression models a binary outcome; something that can take two values such as true/false, yes/no, and so on.\n",
        "\n",
        "In this week you will be doing logistic regression on breast cancer dataset using sklearn library. Feel free to create any new functions required."
      ],
      "metadata": {
        "id": "aTAky_OS1w0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importinf libraries\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "E56ck0_P2NR9"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Data"
      ],
      "metadata": {
        "id": "qojSAol72cmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "breast_cancer = datasets.load_breast_cancer()\n",
        "X, y = breast_cancer.data, breast_cancer.target"
      ],
      "metadata": {
        "id": "_uUSV8Xk2ePh"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#spliting data for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "N6jcbk5g29XW"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Forward pass"
      ],
      "metadata": {
        "id": "ofghhz-63Ru5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_log(x):\n",
        "  pass"
      ],
      "metadata": {
        "id": "K1JzUVko3Zob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Binary cross entropy loss"
      ],
      "metadata": {
        "id": "R4ldHUJs3d2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def BCELoss(y,y_pred):\n",
        "  pass"
      ],
      "metadata": {
        "id": "QkXgo04D3dGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement Logistic Regression here :)"
      ],
      "metadata": {
        "id": "OIuuOJcJ3sti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=y_train.reshape(X_train.shape[0],1)\n",
        "y_test=y_test.reshape(X_test.shape[0],1)"
      ],
      "metadata": {
        "id": "ZLZpoBMAfCuY"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of X_train : \", X_train.shape)\n",
        "print(\"Shape of y_train : \", y_train.shape)\n",
        "print(\"Shape of X_test : \", X_test.shape)\n",
        "print(\"Shape of y_test : \", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXNQsTeMqAHG",
        "outputId": "558dce4e-93c6-4fce-b1cd-65c64c0f9b24"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train :  (455, 30)\n",
            "Shape of y_train :  (455, 1)\n",
            "Shape of X_test :  (114, 30)\n",
            "Shape of y_test :  (114, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1/(1 + np.exp(-x))"
      ],
      "metadata": {
        "id": "xFSBQ5ntqAEs"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def logmodel(X,Y,alpha, iterations):\n",
        "  m=Y.shape[0]\n",
        "  n=X.shape[1]\n",
        "  w=np.zeros((n,1))\n",
        "  b=0\n",
        "  cost_history=[]\n",
        "\n",
        "  for i in range(iterations):\n",
        "    Z=np.dot(X,w)+b\n",
        "    f_wb=sigmoid(Z)\n",
        "\n",
        "    #cost function\n",
        "    cost = -((np.sum(Y * np.log(f_wb) + (1 - Y) * np.log(1 - f_wb))) / (2*m))\n",
        "\n",
        "\n",
        "    dw=(1/m)*np.dot(((f_wb-Y).T),X)\n",
        "    db=(1/m)*np.sum(f_wb-Y)\n",
        "\n",
        "    w=w-(alpha*dw.T)\n",
        "    b=b-alpha*db\n",
        "\n",
        "    cost_history.append(cost)\n",
        "    if i%(iterations/10)==0:\n",
        "      print(f\"the cost after {i} iteration is {cost_history[-1]}\")\n",
        "\n",
        "  return w,b,f_wb\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZbHYa_T0qAB3"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w,b,f=logmodel(X_train,y_train,0.1,10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DRMY_jsh1jH",
        "outputId": "3bca9a03-eddb-4121-aa37-a90e4db2333d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the cost after 0 iteration is 0.34657359027997264\n",
            "the cost after 1000 iteration is 0.020427894488219012\n",
            "the cost after 2000 iteration is 0.01666296182398825\n",
            "the cost after 3000 iteration is 0.014922674653109548\n",
            "the cost after 4000 iteration is 0.013860657186592622\n",
            "the cost after 5000 iteration is 0.013116773847611804\n",
            "the cost after 6000 iteration is 0.012549388656593536\n",
            "the cost after 7000 iteration is 0.012091370528804666\n",
            "the cost after 8000 iteration is 0.011706651535829\n",
            "the cost after 9000 iteration is 0.011373988550930829\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#so the logistic model fitted is y=sigmoid(X*w+b)"
      ],
      "metadata": {
        "id": "FloBnB30zMS_"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=sigmoid(np.dot(X_test,w)+b)\n",
        "for i in range(y_pred.shape[0]):\n",
        "  if y_pred[i]<=0.4:                 #threshold 0.4\n",
        "     y_pred[i]=0\n",
        "  else:\n",
        "     y_pred[i]=1"
      ],
      "metadata": {
        "id": "d8pMYtAUp_TL"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pr=[]\n",
        "for i in range(y_pred.shape[0]):\n",
        "  if y_pred[i]==y_test[i]:\n",
        "    pr.append(1)\n",
        "  else:\n",
        "    pr.append(0)\n",
        "accuracy_score=np.sum(pr)/y_pred.shape[0]\n",
        "print(f\"the accuracy score is {accuracy_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg4sLoOQp_Qy",
        "outputId": "f5244f96-1e13-4d73-acc4-6bb7bba00438"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the accuracy score is 0.9649122807017544\n"
          ]
        }
      ]
    }
  ]
}
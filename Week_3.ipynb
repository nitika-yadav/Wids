{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4lFWhSEEwc9F"
   },
   "source": [
    "#MNIST\n",
    "Our objective is to build a neural network for the classification of the MNIST dataset. This neural network will comprise two layers, each with 10 nodes, and an input layer with 784 nodes corresponding to the image pixels. The specific structure of the neural network is outlined below, where $X$ represents the input, $A^{[0]}$ denotes the first layer, $Z^{[1]}$ signifies the unactivated layer 1, $A^{[1]}$ stands for the activated layer 1, and so forth. The weights and biases are represented by $W$ and $b$ respectively:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDanK4nEwfhh"
   },
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "$A^{[0]}=X$\n",
    "\n",
    "$Z^{[1]}=W^{[1]}A^{[0]}+b^{[1]}$\n",
    "\n",
    "$A^{[1]}=\\text{ReLU}(Z^{[1]})$\n",
    "\n",
    "$Z^{[2]}=W^{[2]}A^{[1]}+b^{[2]}$\n",
    "\n",
    "$A^{[2]}=\\text{softmax}(Z^{[2]})$\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzBJgODl4aDp"
   },
   "source": [
    "You have the flexibility to create any function within or outside the class, allowing you to modify parameters as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "8A6ScQ-8lzWy"
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGVN81yBnufX"
   },
   "source": [
    "### Required functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "N4A3X8zjh5My"
   },
   "outputs": [],
   "source": [
    "# activation and loss functions\n",
    "def ReLU(Z):\n",
    "    return np.maximum(Z, 0)\n",
    "\n",
    "def derivative_ReLU(x):\n",
    "    b = np.array(x>0,dtype = np.float32)\n",
    "    return b\n",
    "\n",
    "def softmax(Z):\n",
    "    A=np.exp(Z)/sum(np.exp(Z))\n",
    "    return A\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Vqdn0Wv0mFNE"
   },
   "outputs": [],
   "source": [
    "#complete the class of neural network\n",
    "\n",
    "class NN:\n",
    "    def __init__(self):\n",
    "        self.W1 = np.random.randn(10, 784) - 0.5\n",
    "        self.W2 = np.random.randn(10, 10) - 0.5\n",
    "        self.b1 = np.random.rand(10, 1) - 0.5\n",
    "        self.b2 = np.random.rand(10, 1) - 0.5\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward_prop(self, X):\n",
    "        self.Z1 = self.W1.dot(X.T) + self.b1\n",
    "        self.A1 = ReLU(self.Z1)\n",
    "        self.Z2 = self.W2.dot(self.A1) + self.b2\n",
    "        self.A2 = softmax(self.Z2)\n",
    "\n",
    "        return self.A2\n",
    "\n",
    "    def one_hot(self, labels, num_classes): \n",
    "        num_samples = len(labels)\n",
    "        one_hot_labels = np.zeros((num_classes, num_samples))\n",
    "\n",
    "        for i in range(num_samples):\n",
    "            one_hot_labels[labels[i], i] = 1\n",
    "\n",
    "        return one_hot_labels\n",
    "\n",
    "    def backward_prop(self, X, Y):\n",
    "        m = X.shape[1] \n",
    "        self.dZ2 = self.A2 - Y\n",
    "        self.dW2 = (1 / m) * self.dZ2.dot(self.A1.T)\n",
    "        self.db2 = (1 / m) * np.sum(self.dZ2)\n",
    "        self.dZ1 = (1/m)*self.W2.T.dot(self.dZ2) * (derivative_ReLU(self.A1))\n",
    "        self.dW1 = (1 / m) * self.dZ1.dot(X)\n",
    "        self.db1 = (1 / m) * np.sum(self.dZ1)\n",
    "    \n",
    "\n",
    "    def update_params(self, alpha):\n",
    "        self.W1 = self.W1 - alpha * self.dW1\n",
    "        self.b1 = self.b1 - alpha * self.db1\n",
    "        self.W2 = self.W2 - alpha * self.dW2\n",
    "        self.b2 = self.b2 - alpha * self.db2\n",
    "\n",
    "    def get_predictions(self):\n",
    "        pass\n",
    "    \n",
    "    def cost_function(self,a,y):\n",
    "        m = (y.T).shape[0]\n",
    "        cost = -(1/m) * np.sum(y * np.log(a))\n",
    "        return cost\n",
    "\n",
    "    def get_accuracy(self, Y):\n",
    "        predictions= np.argmax(self.A2,0)\n",
    "        y=np.argmax(Y,0)\n",
    "        return np.mean(predictions == y)*100\n",
    "\n",
    "    def gradient_descent(self, X, Y, alpha, iterations):\n",
    "        for i in range(iterations):\n",
    "            a2 = self.forward_prop(X)\n",
    "            self.backward_prop(X, Y)\n",
    "            self.update_params(alpha)\n",
    "            cost = self.cost_function(a2, Y)\n",
    "            if i % (iterations / 10) == 0:\n",
    "                print(f\"Iteration {i}, Cost: {cost}\")\n",
    "        return self.W1, self.b1, self.W2, self.b2       \n",
    "                \n",
    "    def make_predictions(self,X):\n",
    "        A2 = self.forward_prop(X)\n",
    "        predictions = np.argmax(A2)\n",
    "        return predictions\n",
    "\n",
    "    def show_prediction(self,x):\n",
    "        idx = random.randrange(0, x.shape[0])\n",
    "        single_image = x[idx,: ].reshape((28, 28))\n",
    "        plt.imshow(single_image, cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "        input_image = x[idx, :].reshape(x[idx, :].shape[0], 1)\n",
    "        prediction = self.make_predictions(input_image.T)\n",
    "\n",
    "        print(\"Model predicts:\", prediction)\n",
    "\n",
    "   \n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FsgNaz6qmoLI"
   },
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "iIbC5z1Lmlcr"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymme4NNNmws9"
   },
   "source": [
    "###preprocessing the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "B8YjLpUwm678"
   },
   "outputs": [],
   "source": [
    "# all values of pixels should be in range[0,1]\n",
    "X_train = (X_train.reshape(X_train.shape[0], -1)/ 255.0)\n",
    "X_test = (X_test.reshape(X_test.shape[0], -1) / 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 60000)\n"
     ]
    }
   ],
   "source": [
    "y_train_encoded = nn.one_hot(y_train,10)\n",
    "y_test_encoded = nn.one_hot(y_test,10)\n",
    "\n",
    "print(y_train_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5dqfE25m7ZD"
   },
   "source": [
    "###Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "G05ggxM1m_n0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Cost: 2.3256479615381975\n",
      "Iteration 100, Cost: 2.325647961538198\n",
      "Iteration 200, Cost: 2.325647961538198\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#training model using gradient descent\u001b[39;00m\n\u001b[0;32m      2\u001b[0m nn \u001b[38;5;241m=\u001b[39m NN()\n\u001b[1;32m----> 3\u001b[0m w1,b1,w2,b2\u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mgradient_descent(X_train, y_train_encoded,\u001b[38;5;241m0.001\u001b[39m,\u001b[38;5;241m1000\u001b[39m)\n",
      "Cell \u001b[1;32mIn[27], line 63\u001b[0m, in \u001b[0;36mNN.gradient_descent\u001b[1;34m(self, X, Y, alpha, iterations)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackward_prop(X, Y)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_params(alpha)\n\u001b[1;32m---> 63\u001b[0m cost \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcost_function(a2, Y)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m (iterations \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m10\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Cost: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[27], line 50\u001b[0m, in \u001b[0;36mNN.cost_function\u001b[1;34m(self, a, y)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcost_function\u001b[39m(\u001b[38;5;28mself\u001b[39m,a,y):\n\u001b[0;32m     49\u001b[0m     m \u001b[38;5;241m=\u001b[39m (y\u001b[38;5;241m.\u001b[39mT)\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 50\u001b[0m     cost \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mm) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum(y \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(a))\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cost\n",
      "File \u001b[1;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36msum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#training model using gradient descent\n",
    "nn = NN()\n",
    "w1,b1,w2,b2= nn.gradient_descent(X_train, y_train_encoded,0.001,1000)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'y' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mmake_predictions(X_test)\n\u001b[1;32m----> 3\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mget_accuracy(y_test_encoded)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy)\n",
      "Cell \u001b[1;32mIn[21], line 55\u001b[0m, in \u001b[0;36mNN.get_accuracy\u001b[1;34m(self, Y)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_accuracy\u001b[39m(\u001b[38;5;28mself\u001b[39m, Y):\n\u001b[0;32m     54\u001b[0m     predictions\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA2,\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 55\u001b[0m     y\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39margmax(y,\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(predictions \u001b[38;5;241m==\u001b[39m y)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'y' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "y_pred = nn.make_predictions(X_test)\n",
    "\n",
    "accuracy = nn.get_accuracy(y_test_encoded)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nn\u001b[38;5;241m.\u001b[39mshow_prediction(\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[21], line 74\u001b[0m, in \u001b[0;36mNN.show_prediction\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow_prediction\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[1;32m---> 74\u001b[0m     idx \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandrange(\u001b[38;5;241m0\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     75\u001b[0m     single_image \u001b[38;5;241m=\u001b[39m x[idx,: ]\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m))\n\u001b[0;32m     76\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(single_image, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "nn.show_prediction(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sa-CT3UnnAsr"
   },
   "source": [
    "### Viewing Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "WV9UEIHbnJKd"
   },
   "outputs": [],
   "source": [
    "#viewing prediction for 10 random images in dataset"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
